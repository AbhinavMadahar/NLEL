# Teach AI to Think in Equilibria: A Minimal Interdisciplinary Core for Computer Scientists

**Subtitle:** Why AI curricula should require macroeconomics and political institutions to improve safety‑relevant reasoning

**Author:** Abhinav Madahar (अभिनव ਮਦਾਹਰ)

**Abstract (≈140 words).** Many computer scientists discuss the downstream effects of artificial intelligence—on labor markets, energy systems, and governance—without using the formal tools that economists and political scientists have developed. I argue for a minimal interdisciplinary core for AI‑bound students: one course in macroeconomics (externalities, general equilibrium, and growth under technology shocks) and one in political institutions (electoral systems, veto‑player theory, and principal–agent models). The goal is not to turn computer scientists into social scientists, but to equip the people building general‑purpose technologies to reason about the social systems in which their work is deployed. The piece outlines a concrete curricular template, two short analytic vignettes (energy and labor), and practical steps departments can take without increasing time‑to‑degree.

**Problem.** When asked about the societal consequences of advances in artificial intelligence, many computer scientists answer from intuition rather than from established frameworks in economics, political science, or sociology. Exceptional technical training should also prepare students to reason within those frameworks, so that they can anticipate second‑order effects and institutional constraints—not just build systems.

**Claim.** If we expect researchers to forecast how advances in AI will affect labor markets, energy systems, or democratic institutions, they need early, structured exposure to those domains. Consider the energy transition. The net environmental impact of increasingly capable AI depends not only on model and infrastructure design but also on state capacity to implement expert‑endorsed yet politically costly policies—such as expanding nuclear fission. Whether such policies are feasible is illuminated by political‑economy models (e.g., veto‑player theory, median‑voter dynamics) that most computer‑science curricula do not cover.

**A minimal core.** I propose a two‑course requirement for students on AI tracks:
1) *Principles of Macroeconomics*, emphasizing externalities, general‑equilibrium reasoning, and growth models under technology shocks; and
2) *Foundations of Democratic Institutions*, covering electoral systems, legislatures, bureaucratic capacity, and public‑choice models of regulation.

This is not about turning computer scientists into economists or political scientists. It is about ensuring that the people building general‑purpose technologies can reason about the social systems in which those technologies are deployed. The alternative is safety‑critical research conducted without robust tools for thinking about diffusion, incentives, and governance.

**Analytic vignette: energy demand and political feasibility.** Suppose training and serving frontier models raises electricity demand by δ percent in the next five years. A purely technical view might compare emissions under different datacenter efficiency trajectories. A model‑based view asks a different question: under which institutional configurations does a low‑carbon baseload expansion (e.g., new fission capacity) actually occur? In a veto‑player framework, policy change requires consent from all effective veto actors (executive, two legislative chambers, independent regulators, and sometimes courts). As the number of veto players or their ideological dispersion grows, the win‑set of feasible change shrinks, reducing the likelihood of timely deployment—even if expert consensus is strong. The forecast for AI’s environmental impact thus hinges on institutional parameters, not only on engineering assumptions.

**Analytic vignette: labor markets and distribution.** A standard partial‑equilibrium story might predict that automation displaces routine tasks and increases demand for complementary skills. A general‑equilibrium view forces us to track relative‑price changes, induced innovation, and fiscal feedbacks. If AI systems increase total factor productivity unevenly across sectors, wage effects depend on substitution elasticities and on the tax‑and‑transfer system’s response. Policy sensitivity is high: with stronger automatic stabilizers, transitional unemployment and inequality can be dampened; without them, adjustment costs spike. Students trained to write down—even informally—the relevant objects (production functions, household preferences, government budget constraints) will make more reliable forecasts and design better experiments.

**Implementation in CS curricula.** Departments can adopt the core without extending time‑to‑degree by:
• Cross‑listing existing macro and institutions courses as “AI‑relevant social‑science core.”
• Building short, model‑based assignments into ML/AI courses (e.g., a 2‑page equilibrium analysis tied to a course project).
• Offering a one‑credit reading/recitation that connects models to current AI topics (compute markets, safety externalities, standards).
• Assessing with problem sets that require students to articulate assumptions and trace implications—not opinion pieces.

**Addressing common objections.**
*“Isn’t ethics enough?”* Ethics is necessary but not sufficient. Normative frameworks need positive models to predict effects of policy and design choices.
*“Won’t this crowd out math or systems?”* The proposal substitutes for free electives, not core math/systems. The marginal benefit for safety‑relevant reasoning is large.
*“Aren’t students already overloaded?”* Many programs already require breadth. The two‑course core provides principled breadth targeted to AI’s externalities and governance questions.

**Call to action.** Departments routinely require probability, linear algebra, and algorithms. They should likewise require one macroeconomics course and one institutions course for AI‑bound students. That change would improve the quality of our discourse about AI’s downstream effects and produce researchers who can responsibly anticipate how their work will reshape the world.

**Acknowledgment.** This piece substantially revises and extends a shorter personal note published on May 2, 2025.

**Selected references**
1. Arrow, K. J., & Debreu, G. (1954). “Existence of an Equilibrium for a Competitive Economy.” Econometrica 22(3): 265–290.
2. Downs, A. (1957). An Economic Theory of Democracy. Harper & Row.
3. Tsebelis, G. (2002). Veto Players: How Political Institutions Work. Princeton University Press.
4. Autor, D. H. (2015). “Why Are There Still So Many Jobs? The History and Future of Workplace Automation.” Journal of Economic Perspectives 29(3): 3–30.
5. Winner, L. (1980). “Do Artifacts Have Politics?” Daedalus 109(1): 121–136.
6. Ostrom, E. (1990). Governing the Commons: The Evolution of Institutions for Collective Action. Cambridge University Press.
