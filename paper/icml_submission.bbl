\begin{thebibliography}{8}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Gao et~al.(2023)Gao, Madaan, Zhou, Alon, Liu, Yang, and
  Neubig]{gao2023pal}
Gao, L., Madaan, A., Zhou, Y., Alon, U., Liu, P., Yang, Y., and Neubig, G.
\newblock Pal: Program-aided language models.
\newblock \emph{arXiv preprint arXiv:2211.10435}, 2023.

\bibitem[Schick et~al.(2023)Schick, Dwivedi-Yu, Dess{\`i}, Raunak, Havrilla,
  Scialom, Chen, Niehues, Schulte, Zettlemoyer, Schmid, and
  Petroni]{schick2023toolformer}
Schick, T., Dwivedi-Yu, J., Dess{\`i}, R., Raunak, V., Havrilla, A., Scialom,
  T., Chen, X., Niehues, J., Schulte, S., Zettlemoyer, L., Schmid, M., and
  Petroni, F.
\newblock Toolformer: Language models can teach themselves to use tools.
\newblock \emph{arXiv preprint arXiv:2302.04761}, 2023.

\bibitem[Shen et~al.()Shen, Liu, Chen, Xu, Wang, Zhang, Liang, Huang, Chen, and
  Zhang]{shen2023hugginggpt}
Shen, Y., Liu, K., Chen, W., Xu, X., Wang, F., Zhang, Z., Liang, X., Huang, J.,
  Chen, Z., and Zhang, Y.
\newblock Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging
  face.

\bibitem[Shinn et~al.(2023)Shinn, Labash, and Madaan]{shinn2023reflexion}
Shinn, N., Labash, T., and Madaan, A.
\newblock Reflexion: Language agents with verbal reinforcement learning.
\newblock \emph{arXiv preprint arXiv:2303.11366}, 2023.

\bibitem[Wang et~al.(2022)Wang, Wei, Schuurmans, Le, Chi, and
  Zhou]{wang2022selfconsistency}
Wang, X., Wei, J., Schuurmans, D., Le, Q., Chi, E.~H., and Zhou, D.
\newblock Self-consistency improves chain of thought reasoning in language
  models.
\newblock \emph{arXiv preprint arXiv:2203.11171}, 2022.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le,
  and Zhou]{wei2022chain}
Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le,
  Q., and Zhou, D.
\newblock Chain-of-thought prompting elicits reasoning in large language
  models.
\newblock \emph{arXiv preprint arXiv:2201.11903}, 2022.

\bibitem[Yao et~al.(2023{\natexlab{a}})Yao, Yu, Zhao, Yu, Welleck, and
  Radev]{yao2023tree}
Yao, S., Yu, D., Zhao, J., Yu, I.~S., Welleck, S., and Radev, D.
\newblock Tree of thoughts: Deliberate problem solving with large language
  models.
\newblock \emph{arXiv preprint arXiv:2305.10601}, 2023{\natexlab{a}}.

\bibitem[Yao et~al.(2023{\natexlab{b}})Yao, Zhao, Yu, Wang, and
  Radev]{yao2023react}
Yao, S., Zhao, J., Yu, D., Wang, N.~D., and Radev, D.
\newblock React: Synergizing reasoning and acting in language models.
\newblock \emph{arXiv preprint arXiv:2210.03629}, 2023{\natexlab{b}}.

\end{thebibliography}
